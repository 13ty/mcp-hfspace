[
    {
      label: "Input Text",
      type: "string",
      python_type: {
        type: "str",
        description: "",
      },
      component: "Textbox",
      example_input: "Howdy!",
      serializer: "StringSerializable",
      description: undefined,
    },
    {
      label: "Acoustic Prompt",
      type: "",
      python_type: {
        type: "Any",
        description: "any valid value",
      },
      component: "Dropdown",
      example_input: null,
      serializer: "SimpleSerializable",
      description: "any valid value",
    },
  ]
  
  
  Come back to SUNO/BARK
  
  [
    {
      label: "Input Text",
      type: "string",
      python_type: {
        type: "str",
        description: "",
      },
      component: "Textbox",
      example_input: "Howdy!",
      serializer: "StringSerializable",
      description: undefined,
    },
    {
      label: "Acoustic Prompt",
      type: "",
      python_type: {
        type: "Any",
        description: "any valid value",
      },
      component: "Dropdown",
      example_input: null,
      serializer: "SimpleSerializable",
      description: "any valid value",
    },
  ]
  
  {
    parameters: [
      {
        label: "Upload Image",
        parameter_name: "img",
        parameter_has_default: false,
        parameter_default: null,
        type: "Blob | File | Buffer",
        python_type: {
          type: "Dict(path: str | None (Path to a local file), url: str | None (Publicly available url or base64 encoded image), size: int | None (Size of image in bytes), orig_name: str | None (Original filename), mime_type: str | None (mime type of image), is_stream: bool (Can always be set to False), meta: Dict())",
          description: "For input, either path or url must be provided. For output, path is always provided.",
        },
        component: "Image",
        example_input: {
          path: "https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png",
          meta: {
            _type: "gradio.FileData",
          },
          orig_name: "bus.png",
          url: "https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png",
        },
        description: undefined,
      },
      {
        label: "Object to Extract",
        parameter_name: "prompt",
        parameter_has_default: false,
        parameter_default: null,
        type: "string",
        python_type: {
          type: "str",
          description: "",
        },
        component: "Textbox",
        example_input: "Hello!!",
        description: undefined,
      },
      {
        label: "Background Prompt (optional)",
        parameter_name: "bg_prompt",
        parameter_has_default: true,
        parameter_default: null,
        type: "string",
        python_type: {
          type: "str",
          description: "",
        },
        component: "Textbox",
        example_input: "Hello!!",
        description: undefined,
      },
      {
        label: "Aspect Ratio",
        parameter_name: "aspect_ratio",
        parameter_has_default: true,
        parameter_default: "1:1",
        type: "string",
        python_type: {
          type: "Literal['1:1', '16:9', '9:16', '4:3']",
          description: "",
        },
        component: "Dropdown",
        example_input: "1:1",
        description: undefined,
      },
      {
        component: "state",
        example: null,
        parameter_default: null,
        parameter_has_default: true,
        parameter_name: null,
        hidden: true,
        description: undefined,
        type: "",
      },
      {
        label: "Object Size (%)",
        parameter_name: "scale_percent",
        parameter_has_default: true,
        parameter_default: 50,
        type: "number",
        python_type: {
          type: "float",
          description: "",
        },
        component: "Slider",
        example_input: 10,
        description: "numeric value between 10 and 200",
      },
    ],
    returns: [
      {
        label: "Combined Result",
        type: "string",
        python_type: {
          type: "Dict(path: str | None (Path to a local file), url: str | None (Publicly available url or base64 encoded image), size: int | None (Size of image in bytes), orig_name: str | None (Original filename), mime_type: str | None (mime type of image), is_stream: bool (Can always be set to False), meta: Dict())",
          description: "",
        },
        component: "Image",
        description: undefined,
      },
      {
        label: "Extracted Object",
        type: "string",
        python_type: {
          type: "Dict(path: str | None (Path to a local file), url: str | None (Publicly available url or base64 encoded image), size: int | None (Size of image in bytes), orig_name: str | None (Original filename), mime_type: str | None (mime type of image), is_stream: bool (Can always be set to False), meta: Dict())",
          description: "",
        },
        component: "Image",
        description: undefined,
      },
    ],
    type: {
      generator: false,
      cancel: false,
    },
  }
  
  
  
  [
    {
      label: "Input Screenshot",
      parameter_name: "image",
      parameter_has_default: false,
      parameter_default: null,
      type: "Blob | File | Buffer",
      python_type: {
        type: "Dict(path: str | None (Path to a local file), url: str | None (Publicly available url or base64 encoded image), size: int | None (Size of image in bytes), orig_name: str | None (Original filename), mime_type: str | None (mime type of image), is_stream: bool (Can always be set to False), meta: Dict())",
        description: "For input, either path or url must be provided. For output, path is always provided.",
      },
      component: "Image",
      example_input: {
        path: "https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png",
        meta: {
          _type: "gradio.FileData",
        },
        orig_name: "bus.png",
        url: "https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png",
      },
      description: undefined,
    },
    {
      label: "Query",
      parameter_name: "query",
      parameter_has_default: false,
      parameter_default: null,
      type: "string",
      python_type: {
        type: "str",
        description: "",
      },
      component: "Textbox",
      example_input: "Hello!!",
      description: undefined,
    },
    {
      label: "Refinement Steps",
      parameter_name: "iterations",
      parameter_has_default: true,
      parameter_default: 1,
      type: "number",
      python_type: {
        type: "float",
        description: "",
      },
      component: "Slider",
      example_input: 1,
      description: "numeric value between 1 and 3",
    },
    {
      label: "Is Example Image",
      parameter_name: "is_example_image",
      parameter_has_default: true,
      parameter_default: "False",
      type: "string",
      python_type: {
        type: "Literal['True', 'False']",
        description: "",
      },
      component: "Dropdown",
      example_input: "True",
      description: undefined,
    },
  ]
  

  [
    {
      label: "Input",
      parameter_name: "query",
      parameter_has_default: false,
      parameter_default: null,
      type: "string",
      python_type: {
        type: "str",
        description: "",
      },
      component: "Textbox",
      example_input: "Hello!!",
      description: undefined,
    },
    {
      label: "Qwen2.5-72B-Instruct",
      parameter_name: "history",
      parameter_has_default: true,
      parameter_default: [
      ],
      type: "",
      python_type: {
        type: "Tuple[str | Dict(file: filepath, alt_text: str | None) | Dict(component: str, value: Any, constructor_args: Dict(), props: Dict()) | None, str | Dict(file: filepath, alt_text: str | None) | Dict(component: str, value: Any, constructor_args: Dict(), props: Dict()) | None]",
        description: "",
      },
      component: "Chatbot",
      example_input: [
        [
          "Hello!",
          null,
        ],
      ],
      description: undefined,
    },
    {
      label: "parameter_8",
      parameter_name: "system",
      parameter_has_default: true,
      parameter_default: "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.",
      type: "string",
      python_type: {
        type: "str",
        description: "",
      },
      component: "Textbox",
      example_input: "Hello!!",
      description: undefined,
    },
  ]




  [
    {
      label: "Prompt",
      parameter_name: "prompt",
      parameter_has_default: false,
      parameter_default: null,
      type: "string",
      python_type: {
        type: "str",
        description: "",
      },
      component: "Textbox",
      example_input: "Hello!!",
      description: undefined,
    },
    {
      label: "Seed",
      parameter_name: "seed",
      parameter_has_default: true,
      parameter_default: 0,
      type: "number",
      python_type: {
        type: "float",
        description: "numeric value between 0 and 2147483647",
      },
      component: "Slider",
      example_input: 0,
      description: "numeric value between 0 and 2147483647",
    },
    {
      label: "Randomize seed",
      parameter_name: "randomize_seed",
      parameter_has_default: true,
      parameter_default: true,
      type: "boolean",
      python_type: {
        type: "bool",
        description: "",
      },
      component: "Checkbox",
      example_input: true,
      description: undefined,
    },
    {
      label: "Width",
      parameter_name: "width",
      parameter_has_default: true,
      parameter_default: 1024,
      type: "number",
      python_type: {
        type: "float",
        description: "numeric value between 256 and 2048",
      },
      component: "Slider",
      example_input: 256,
      description: "numeric value between 256 and 2048",
    },
    {
      label: "Height",
      parameter_name: "height",
      parameter_has_default: true,
      parameter_default: 1024,
      type: "number",
      python_type: {
        type: "float",
        description: "numeric value between 256 and 2048",
      },
      component: "Slider",
      example_input: 256,
      description: "numeric value between 256 and 2048",
    },
    {
      label: "Number of inference steps",
      parameter_name: "num_inference_steps",
      parameter_has_default: true,
      parameter_default: 4,
      type: "number",
      python_type: {
        type: "float",
        description: "numeric value between 1 and 50",
      },
      component: "Slider",
      example_input: 1,
      description: "numeric value between 1 and 50",
    },
  ]